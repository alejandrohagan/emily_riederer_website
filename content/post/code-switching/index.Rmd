---
output: hugodown::md_document
title: "Code Switching"
subtitle: ""
summary: "How different languages reflect the context of their creation"
authors: []
tags: [rstats]
categories: []
date: 2022-09-03
lastmod: 2022-09-03
featured: false
draft: false
aliases:

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: "Art by the inimitable [Allison Horst](https://twitter.com/allison_horst?lang=en), as first seen in JD Long's [rstudio::conf(2019)](https://cerebralmastication.com/2019/01/18/slides-from-rstudio-conf-2019/) talk"
  focal_point: ""
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: [""]
---

```{r echo = FALSE}
knit_print.data.frame = function(x, ...) {
  res = paste(c("", "", knitr::kable(x)), collapse = "\n")
  knitr::asis_output(res)
}

registerS3method(
  "knit_print", "data.frame", knit_print.data.frame,
  envir = asNamespace("knitr")
)

custom_print <- function(x) {
  paste(knitr::kable(x, format = "markdown"), collapse = "\n")
}
knitr::opts_knit$set(sql.print = custom_print)
```


Interoperability work:
+ Posit
+ dbt python models
+ arrow

Big picture really powerful; however not just a technical problem but a cultural one

Reasonable defaults change by language 

## Object Representation (R vs Python)

```{r, results = 'hold'}
x = 1:3
y = x
x[4] = 4
print(x)
print(y)
```

```{python, results = 'hold'}
x = [1,2,3]
y = x 
x.append(4)
print(x)
print(y)
```

```{python, results = 'hold'}
import numpy as np
x = np.array([1,2,3])
y = x
x = x * 5
print(x)
print(y)
```

## Null Handling (R vs SQL)

```{r echo = FALSE}
library(DBI)
library(duckdb)
con <- dbConnect(duckdb())
df <- data.frame(x = c(1,2,NA), y = 3:5)
df1 <- data.frame(A = 1, B = NA, X = TRUE)
df2 <- data.frame(A = 1, B = NA, Y = FALSE)
dbWriteTable(con, "tbl", df)
dbWriteTable(con, "tbl1", df1)
dbWriteTable(con, "tbl2", df2)
```

### Aggregation

R defaults to NA for column
SQL allows
Python: numpy disallows, but works in pandas agg

```{r}
x <- c(1,2,NA)
sum(x)

df <- data.frame(x = x)
dplyr::summarize(df, x = sum(x))
```

```{sql, connection = con}
select sum(x)
from tbl
```

```{python}
import pandas as pd
import numpy as np
x = [1,2,np.nan]
y = [3,4,5]
df = pd.DataFrame({'x':x,'y':y})
sum(x)
np.sum(x)
df.agg({'x': ['sum']})
```

### Transformation

No one allows its

```{r}
dplyr::mutate(df, z = x-y)

df$z <- with(df, x-y)
df
```

```{sql, connection = con}
select *, x-y as z
from tbl
```

```{python}
np.array(x) - np.array(y)
df.assign(z = lambda d: d.x - d.y)
```


### Joining 

SQL doesn't recognize, by default R and python do

```{sql, connection = con}
select tbl1.*, tbl2.Y 
from 
  tbl1 inner join tbl2 
  on 
  tbl1.A = tbl2.A and 
  tbl1.B = tbl2.B
```

```{r results = "hold"}
merge(df1, df2, by = c("A", "B"))
dplyr::inner_join(df1, df2, by = c("A", "B"))
# merge(df1, df2, by = c("A","B"), incomparables = NA)
# dplyr::inner_join(df1, df2, by = c("A", "B"), na_matches = "never")
```

```{python}
import numpy as np
import pandas as pd
df1 = pd.DataFrame([[1, np.nan, True]], columns = ['A','B','X'])
df2 = pd.DataFrame([[1, np.nan, False]], columns = ['A','B','Y'])
pd.merge(df1, df2)
```

### Filtering

SQL doesn't recognize

Neither R nor dplyr give data back, but do so in different ways

pandas does recognize

```{sql, connection = con}
select A, B, X 
from tbl1 
where B != 1
```

```{r}
df1[df1$B != 1,]
dplyr::filter(df1, B != 1)
```

```{python}
df1[df1.B != 1]
df1.query('B != 1')
```

## Example

```{r echo = FALSE}
df_monthly_spend <- data.frame(
  STORE_ID = rep(c(1,2,NA), 3),
  MONTH = rep(c(1, 2, 3), each = 3),
  AMT_SPEND = c(rnorm(8, 100), NA)
)

df_monthly_return <- data.frame(
  STORE_ID = rep(c(1,2,NA), 3),
  MONTH = rep(c(1, 2, 3), each = 3),
  AMT_RETURN = c(NA, rnorm(8, 100)/10)
)

dbWriteTable(con, "spend", df_monthly_spend, overwrite = TRUE)
dbWriteTable(con, "returns", df_monthly_return, overwrite = TRUE)
```

Average spend per month?

```{sql connection = con}
select 
  store_id, 
  avg(amt_spend), 
  sum(amt_spend) / count(amt_spend), 
  sum(amt_spend) / count(1)
from spend
group by 1
order by 1
```

Net sales?

```{sql connection = con}
select 
  spend.*,
  returns.amt_return
from 
  spend
  inner join
  returns 
  on
  spend.store_id = returns.store_id and
  spend.month = returns.month
```

```{sql connection = con}
select
  spend.*,
  returns.amt_return
from 
  spend
  inner join
  returns 
  on
  coalesce(spend.store_id, 999) = coalesce(returns.store_id, 999) and
  spend.month = returns.month
```

```{sql connection = con}
select
  spend.month, 
  sum(amt_spend - amt_return) as net_spend
from 
  spend
  inner join
  returns 
  on
  coalesce(spend.store_id, 999) = coalesce(returns.store_id, 999) and
  spend.month = returns.month
group by 1
order by 1
```


```{sql connection = con}
select
  spend.month, 
  amt_spend,
  amt_return,
  amt_spend - amt_return as net_spend
from 
  spend
  inner join
  returns 
  on
  coalesce(spend.store_id, 999) = coalesce(returns.store_id, 999) and
  spend.month = returns.month
```

```{sql connection = con}
select
  spend.month, 
  sum(coalesce(amt_spend,0) - coalesce(amt_return,0)) as net_spend
from 
  spend
  inner join
  returns 
  on
  coalesce(spend.store_id, 999) = coalesce(returns.store_id, 999) and
  spend.month = returns.month
group by 1
order by 1
```

## Logistic Regression (R vs python)

## Feature Importance (R vs Spark)

## Conclusion
